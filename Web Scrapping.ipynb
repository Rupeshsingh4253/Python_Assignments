{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Web Scraping:\n",
    "\n",
    "Definition: Web scraping is the automated extraction of data from websites. It involves fetching the HTML of a web page and \n",
    "then extracting information of interest.\n",
    "\n",
    "Why it's Used:\n",
    "\n",
    "Data Collection: Extracting data for analysis or research.\n",
    "Price Monitoring: Tracking prices of products on e-commerce sites.\n",
    "Market Research: Gathering information about competitors.\n",
    "Q2. Methods for Web Scraping:\n",
    "\n",
    "1. Manual Copy-Pasting:\n",
    "\n",
    "Manual extraction of data by copying and pasting.\n",
    "2. Use of Automated Tools:\n",
    "\n",
    "Tools like Octoparse or Import.io can be used for point-and-click scraping.\n",
    "3. Writing Code:\n",
    "\n",
    "Using programming languages (e.g., Python with libraries like Requests and Beautiful Soup) to automate the process.\n",
    "Q3. Beautiful Soup:\n",
    "\n",
    "Definition: Beautiful Soup is a Python library for pulling data out of HTML and XML files. It provides Pythonic idioms for \n",
    "    iterating, searching, and modifying the parse tree.\n",
    "\n",
    "Use:\n",
    "\n",
    "Beautiful Soup simplifies the process of web scraping by providing Pythonic methods for navigating and searching the parse tree.\n",
    "It transforms a complex HTML document into a tree of Python objects, such as tags, navigable strings, or comments.\n",
    "Q4. Flask in Web Scraping Project:\n",
    "\n",
    "Use:\n",
    "Flask is a web framework for Python, used to build web applications.\n",
    "In a web scraping project, Flask might be used to create a web interface for users to input parameters, initiate the scraping \n",
    "process, and display the results.\n",
    "Flask provides a convenient way to expose the functionality of a web scraper through a user-friendly interface.\n",
    "Q5. AWS Services in the Project:\n",
    "\n",
    "1. AWS Lambda:\n",
    "\n",
    "Use: Serverless compute service. It can be used to run the web scraping code in response to events without provisioning or \n",
    "managing servers.\n",
    "2. AWS API Gateway:\n",
    "\n",
    "Use: API Gateway can be used to create, publish, and manage APIs. In the context of web scraping, it could expose an API\n",
    "    endpoint for triggering the scraping process.\n",
    "3. AWS S3 (Simple Storage Service):\n",
    "\n",
    "Use: S3 can be used to store the scraped data. It provides scalable object storage with features like versioning and access \n",
    "    control.\n",
    "4. AWS DynamoDB:\n",
    "\n",
    "Use: A NoSQL database service that could be used to store structured data obtained from web scraping.\n",
    "5. AWS CloudWatch:\n",
    "\n",
    "Use: Monitoring service that can be used to track and log events from the web scraping process.\n",
    "6. AWS IAM (Identity and Access Management):\n",
    "\n",
    "Use: IAM can be used to manage access and permissions for the different AWS services involved in the project, ensuring \n",
    "    security and compliance.\n",
    "7. AWS CloudFormation:\n",
    "\n",
    "Use: Infrastructure as Code (IaC) service that can be used to define and deploy AWS resources in a controlled and predictable\n",
    "    manner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
